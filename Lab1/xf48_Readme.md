# Lab1 Report

Xy Fang (xf48)

>  Collaborator: Yuxiang Chen (yc825) | Yutong Zou (yz2664)



## Part A. Build Your Clonebot

Done.
 [Photo]

## Part B. Plan

\*\***Describe your setting, players, activity and goals here.**\*\*

**Setting**

We have specifically designed five different robot use cases of the clone bot with all in the same settings: desktop home-use/business-use helper bot. Each of the ideas captures one of the common scenarios when humans perform certain tasks on a desktop. 

### B.1 Angel Bot

*   **Players**

    The major players in angel bot use cases are human and angel bot. The most common scenario is when the human is alone and needing comforting to a certain degree. 

*   **Activity**

    When the human user sits by the table, the angle bot will be able to use its camera and other sensors to capture the emotion status of the user. Then the Angel Bot will approach the user on the desktop and make communication with the user through physical comforting and verbal chatting. 

*   **Goals**

    The goal of the Angel Bot is to comfort the user and provide emotional support like e-pets, while the goal of the user is to receive companionship and support from the robot through passively receiving the comfort. 

### B.2 Butter Bot

*   **Players**

    Everyone on the dining table is involved in the scene. Whoever needs the butter could be involved in the interaction with the bot. Also, people in the room could be watching the interaction.

*   **Activity**

    The ButterBot always holds a piece of butter. When someone says “droid, pass the butter”, the ButterBot would come to this person and stop within the reachable distance. Once it detects the person finishes using the butter, the ButterBot would ask “what is my purpose, Sire?” When the person answers “you pass butter”, the ButterBot would shake its head shouting “nooooooo!”

*   **Goals**

    The goal of the bot is to pass the butter and amuse people. The goal of the person who needs the butter is to call the bot to pass the butter, take the butter and tell the bot its purpose.

### B.3 Charger Bot

*   **Players**

    The players in the ChargerBot scenario are only the bot and the human user who’s operating a laptop on the desktop (and the laptop).

*   **Activity**

    ChargerBot will be able to detect the vibration and hand gestures of the user and automatically hold the charging cable to approach the charging port of the laptop. In an ideal scenario, it will be able to detect and aim for the charging port automatically and charge the laptop upon request. On the other hand, it can also be a remote charger for phone/smartwatches, and automatically come closer to the devices and charge it upon gesture request. Users will also be able to tap on the desktop using gestures to tell the ChargerBot to go back to its base hub to clear out the desktop when charging is not needed. 

*   **Goals**

    The goal of the chargerbot is to provide an automated experience on the desktop to plug in laptops without looking for the charger all over the place. It also serves the purpose of an organizer which keeps the desktop free of cables when charging is not needed. The goal of the user is to have a better desktop management experience, and also to have a smart home experience down to every detail in living experiences. 

### B.4 Gaming Bot

*   **Players**

    

*   **Activity**

    

*   **Goals**




### B.5 Printer Bot

*   **Players**

    

*   **Activity**

    

*   **Goals**



\*\***Include pictures of your storyboards here**\*\*

### B.1 Angel Bot

<img src="https://s2.loli.net/2023/02/07/WurUE2IjZBSzHyf.jpg" alt="angelbot.JPG" style="zoom:15%;" />

### B.2 Butter Bot

<img src="https://s2.loli.net/2023/02/07/eOpwTxmdQP24Ej6.jpg" alt="butterbot.JPG" style="zoom:15%;" />

### B.3 Charger Bot

<img src="https://s2.loli.net/2023/02/07/M6CtOj2W3KaHvmb.jpg" alt="chargerbot.JPG" style="zoom:15%;" />

### B.4 Gaming Bot

<img src="https://s2.loli.net/2023/02/07/wYDe1Flt9ChjgPR.jpg" alt="gamingbot.JPG" style="zoom:15%;" />

### B.5 Printer Bot

<img src="https://s2.loli.net/2023/02/07/jkQr8YC46vuHPSc.jpg" alt="printerbot.JPG" style="zoom:15%;" />



## Part C. Act out the Interaction

Link to the interaction videos are listed below:

*   [AngelBot](https://drive.google.com/file/d/1FY6_9I-aUg-nGc15kKCdiZ49_40MxGPP/view?usp=sharing)

*   [ButterBot](https://drive.google.com/file/d/1FVLrkQnKbNo6o-FCz2TUrYxwon71P2kS/view?usp=sharing)

*   [ChargerBot](https://drive.google.com/file/d/1FTfcvH7BQL_zlZ__33YOo56Ef6-FVGg9/view?usp=sharing)

\*\***Are there things that seemed better on paper than acted out?**\*\*

As we progressed through the act out process of our ideas, for our Butterbot idea, we anticipated that to be able to have more interaction with the user, like actually passing the butter to the user, but because of the physical location and other factors, it still feels like the user need to go through effort to take the butter from the robot. Also for the charger bot, we have found out that it’s really hard to just directly detect where the charging port is and charge the cable onto it, which results in the user interference eventually, and that’s not as smart and as automatic as we expected. 

\*\***Are there new ideas that occur to you or your collaborators that come up from the acting?**\*\*

When acting out some of our ideas, we have come up with some new ideas like how we might change the charging bot to suit different devices like smartphones and smartwatches. We have also envisioned some other use cases for the PrinterBot, like hand follows and remote control instruction in classes. For the AngelBot, we have also imagined it could be more interactive with verbal communication and other types of physical interactions. 
