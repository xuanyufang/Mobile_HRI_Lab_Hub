# Lab1 Report

Xy Fang (xf48)

>  Collaborator: Yuxiang Chen (yc825) | Yutong Zou (yz2664)



## Part A. Build Your Clonebot

Done.


![WeChat Image_20230206222109](https://user-images.githubusercontent.com/42874337/217140150-067791e5-0428-4281-8602-054001fc4f23.jpg)

## Part B. Plan

\*\***Describe your setting, players, activity and goals here.**\*\*

**Setting**

We have specifically designed five different robot use cases of the clone bot with all in the same settings: desktop home-use/business-use helper bot. Each of the ideas captures one of the common scenarios when humans perform certain tasks on a desktop. 

### B.1 Angel Bot

*   **Players**

    The major players in angel bot use cases are human and angel bot. The most common scenario is when the human is alone and needing comforting to a certain degree. 

*   **Activity**

    When the human user sits by the table, the angle bot will be able to use its camera and other sensors to capture the emotion status of the user. Then the Angel Bot will approach the user on the desktop and make communication with the user through physical comforting and verbal chatting. 

*   **Goals**

    The goal of the Angel Bot is to comfort the user and provide emotional support like e-pets, while the goal of the user is to receive companionship and support from the robot through passively receiving the comfort. 

### B.2 Butter Bot

*   **Players**

    Everyone on the dining table is involved in the scene. Whoever needs the butter could be involved in the interaction with the bot. Also, people in the room could be watching the interaction.

*   **Activity**

    The ButterBot always holds a piece of butter. When someone says “droid, pass the butter”, the ButterBot would come to this person and stop within the reachable distance. Once it detects the person finishes using the butter, the ButterBot would ask “what is my purpose, Sire?” When the person answers “you pass butter”, the ButterBot would shake its head shouting “nooooooo!”

*   **Goals**

    The goal of the bot is to pass the butter and amuse people. The goal of the person who needs the butter is to call the bot to pass the butter, take the butter and tell the bot its purpose.

### B.3 Charger Bot

*   **Players**

    The players in the ChargerBot scenario are only the bot and the human user who’s operating a laptop on the desktop (and the laptop).

*   **Activity**

    ChargerBot will be able to detect the vibration and hand gestures of the user and automatically hold the charging cable to approach the charging port of the laptop. In an ideal scenario, it will be able to detect and aim for the charging port automatically and charge the laptop upon request. On the other hand, it can also be a remote charger for phone/smartwatches, and automatically come closer to the devices and charge it upon gesture request. Users will also be able to tap on the desktop using gestures to tell the ChargerBot to go back to its base hub to clear out the desktop when charging is not needed. 

*   **Goals**

    The goal of the chargerbot is to provide an automated experience on the desktop to plug in laptops without looking for the charger all over the place. It also serves the purpose of an organizer which keeps the desktop free of cables when charging is not needed. The goal of the user is to have a better desktop management experience, and also to have a smart home experience down to every detail in living experiences. 

### B.4 Gaming Bot

*   **Players**
   
   The players in the GamingBot use case include the bot and player playing FPS (First Person Shooting) Games.

    

*   **Activity**
   
   The GamingBot consists of omniwheels that can move in any directions on a flat surface and mouse that serves as control input that allows player to aim during games. The software of the GamingBot will be equipped with computer vision algorithm that detects object to be aimed at. Once the objects to be aimed at are detected, the GamingBot will move the wheels and make sure the mouse cursor aims precisely at the object.  	
    

*   **Goals**

    The goal of the GamingBot is to create a machine that can aim at targets in the game precisely with speed. Unlike traditional software plug-in that simulates human moves, the GamingBot will be able to input control signals from physical devices which can bypass the detection of anti-cheating softwares. 



### B.5 Printer Bot

*   **Players**

    The PrinterBot use case include the bot and the users using the bots. One scenario of using the PrinterBot  is when user wants to write down the AI generated homework answer on the paper. Another scenario of using the PrinterBot is when users want to draw a larger version of their own artwork.
    

*   **Activity**
   
    The PrinterBot always holds a pen that can write onto a paper. When the users finds an answer for the question they want to investigate in on any AI generated responses such as ChatGPT, the bot will be reading the response of that questions as input. Then, the PrinterBot will be navigating the pen on a piece of paper to write down the response from the input and simulate human handwriting. Besides this, when the user want to draw a larger version or zoom-in into to the very tiny details of their own drawing, they can input their own drawing to the PrinterBot. The PrinterBot will then automatically draw a larger version of the drawing on a piece of paper.
    

*   **Goals**
   
       Writing/drawing is exhausting. It takes time and efforts for human to write/draw things in a refined way. The goal of the PrinterBot is to save time and efforts spend during the process of writing, drawing and copying. The ultimate goal of this bot is to help users focus on the content itself instead of focusing their attention on the exhausted process of writing and drawing. 


\*\***Include pictures of your storyboards here**\*\*

### B.1 Angel Bot

<img src="https://s2.loli.net/2023/02/07/WurUE2IjZBSzHyf.jpg" alt="angelbot.JPG" style="zoom:15%;" />

### B.2 Butter Bot

<img src="https://s2.loli.net/2023/02/07/eOpwTxmdQP24Ej6.jpg" alt="butterbot.JPG" style="zoom:15%;" />

### B.3 Charger Bot

<img src="https://s2.loli.net/2023/02/07/M6CtOj2W3KaHvmb.jpg" alt="chargerbot.JPG" style="zoom:15%;" />

### B.4 Gaming Bot

<img src="https://s2.loli.net/2023/02/07/wYDe1Flt9ChjgPR.jpg" alt="gamingbot.JPG" style="zoom:15%;" />

### B.5 Printer Bot

<img src="https://s2.loli.net/2023/02/07/jkQr8YC46vuHPSc.jpg" alt="printerbot.JPG" style="zoom:15%;" />



## Part C. Act out the Interaction

Link to the interaction videos are listed below:

*   [AngelBot](https://drive.google.com/file/d/1FY6_9I-aUg-nGc15kKCdiZ49_40MxGPP/view?usp=sharing)

*   [ButterBot](https://drive.google.com/file/d/1FVLrkQnKbNo6o-FCz2TUrYxwon71P2kS/view?usp=sharing)

*   [ChargerBot](https://drive.google.com/file/d/1FTfcvH7BQL_zlZ__33YOo56Ef6-FVGg9/view?usp=sharing)

\*\***Are there things that seemed better on paper than acted out?**\*\*

As we progressed through the act out process of our ideas, for our Butterbot idea, we anticipated that to be able to have more interaction with the user, like actually passing the butter to the user, but because of the physical location and other factors, it still feels like the user need to go through effort to take the butter from the robot. Also for the charger bot, we have found out that it’s really hard to just directly detect where the charging port is and charge the cable onto it, which results in the user interference eventually, and that’s not as smart and as automatic as we expected. 

\*\***Are there new ideas that occur to you or your collaborators that come up from the acting?**\*\*

When acting out some of our ideas, we have come up with some new ideas like how we might change the charging bot to suit different devices like smartphones and smartwatches. We have also envisioned some other use cases for the PrinterBot, like hand follows and remote control instruction in classes. For the AngelBot, we have also imagined it could be more interactive with verbal communication and other types of physical interactions. 
